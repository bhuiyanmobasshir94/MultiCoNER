{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entity extraction using bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBtP/gAcfbzvtYXa/h4JFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuiyanmobasshir94/MultiCoNER/blob/main/notebooks/Entity_extraction_using_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHhZGnEgVg4D",
        "outputId": "91f2a1f8-f4eb-4921-9f7a-b52f203e0d59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4YdwoyFRIZk",
        "outputId": "b363535a-be7f-41f9-b654-4d5ee1c090d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.py\n"
          ]
        }
      ],
      "source": [
        "%%file config.py\n",
        "import transformers\n",
        "\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "# BASE_MODEL_PATH = \"../input/bert_base_uncased\"\n",
        "MODEL_PATH = \"model.bin\"\n",
        "TRAINING_FILE = \"input/ner_dataset.csv\"\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    do_lower_case=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file dataset.py\n",
        "import config\n",
        "import torch\n",
        "\n",
        "\n",
        "class EntityDataset:\n",
        "    def __init__(self, texts, pos, tags):\n",
        "        # texts: [[\"hi\", \",\", \"my\", \"name\", \"is\", \"abhishek\"], [\"hello\".....]]\n",
        "        # pos/tags: [[1 2 3 4 1 5], [....].....]]\n",
        "        self.texts = texts\n",
        "        self.pos = pos\n",
        "        self.tags = tags\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        text = self.texts[item]\n",
        "        pos = self.pos[item]\n",
        "        tags = self.tags[item]\n",
        "\n",
        "        ids = []\n",
        "        target_pos = []\n",
        "        target_tag =[]\n",
        "\n",
        "        for i, s in enumerate(text):\n",
        "            inputs = config.TOKENIZER.encode(\n",
        "                s,\n",
        "                add_special_tokens=False\n",
        "            )\n",
        "            # abhishek: ab ##hi ##sh ##ek\n",
        "            input_len = len(inputs)\n",
        "            ids.extend(inputs)\n",
        "            target_pos.extend([pos[i]] * input_len)\n",
        "            target_tag.extend([tags[i]] * input_len)\n",
        "\n",
        "        ids = ids[:config.MAX_LEN - 2]\n",
        "        target_pos = target_pos[:config.MAX_LEN - 2]\n",
        "        target_tag = target_tag[:config.MAX_LEN - 2]\n",
        "\n",
        "        ids = [101] + ids + [102]\n",
        "        target_pos = [0] + target_pos + [0]\n",
        "        target_tag = [0] + target_tag + [0]\n",
        "\n",
        "        mask = [1] * len(ids)\n",
        "        token_type_ids = [0] * len(ids)\n",
        "\n",
        "        padding_len = config.MAX_LEN - len(ids)\n",
        "\n",
        "        ids = ids + ([0] * padding_len)\n",
        "        mask = mask + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        target_pos = target_pos + ([0] * padding_len)\n",
        "        target_tag = target_tag + ([0] * padding_len)\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"target_pos\": torch.tensor(target_pos, dtype=torch.long),\n",
        "            \"target_tag\": torch.tensor(target_tag, dtype=torch.long),\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEZ5TbBZRNA2",
        "outputId": "ff27aa78-9cb0-4129-f77e-0759afb3f74f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file engine.py\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    final_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        _, _, loss = model(**data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        final_loss += loss.item()\n",
        "    return final_loss / len(data_loader)\n",
        "\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    final_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        _, _, loss = model(**data)\n",
        "        final_loss += loss.item()\n",
        "    return final_loss / len(data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p5390TlRa9m",
        "outputId": "86c74432-b5dc-47fa-9039-937b4a62aadf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file model.py\n",
        "import config\n",
        "import torch\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "\n",
        "def loss_fn(output, target, mask, num_labels):\n",
        "    lfn = nn.CrossEntropyLoss()\n",
        "    active_loss = mask.view(-1) == 1\n",
        "    active_logits = output.view(-1, num_labels)\n",
        "    active_labels = torch.where(\n",
        "        active_loss,\n",
        "        target.view(-1),\n",
        "        torch.tensor(lfn.ignore_index).type_as(target)\n",
        "    )\n",
        "    loss = lfn(active_logits, active_labels)\n",
        "    return loss\n",
        "\n",
        "\n",
        "class EntityModel(nn.Module):\n",
        "    def __init__(self, num_tag, num_pos):\n",
        "        super(EntityModel, self).__init__()\n",
        "        self.num_tag = num_tag\n",
        "        self.num_pos = num_pos\n",
        "        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\",return_dict=False)\n",
        "        self.bert_drop_1 = nn.Dropout(0.3)\n",
        "        self.bert_drop_2 = nn.Dropout(0.3)\n",
        "        self.out_tag = nn.Linear(768, self.num_tag)\n",
        "        self.out_pos = nn.Linear(768, self.num_pos)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids, target_pos, target_tag):\n",
        "        o1, _ = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        bo_tag = self.bert_drop_1(o1)\n",
        "        bo_pos = self.bert_drop_2(o1)\n",
        "\n",
        "        tag = self.out_tag(bo_tag)\n",
        "        pos = self.out_pos(bo_pos)\n",
        "\n",
        "        loss_tag = loss_fn(tag, target_tag, mask, self.num_tag)\n",
        "        loss_pos = loss_fn(pos, target_pos, mask, self.num_pos)\n",
        "\n",
        "        loss = (loss_tag + loss_pos) / 2\n",
        "\n",
        "        return tag, pos, loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzfILdDiRkds",
        "outputId": "18f71064-241c-4dc7-9f8e-b20714d23a1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file predict.py\n",
        "import numpy as np\n",
        "\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "import config\n",
        "import dataset\n",
        "import engine\n",
        "from model import EntityModel\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    meta_data = joblib.load(\"meta.bin\")\n",
        "    enc_pos = meta_data[\"enc_pos\"]\n",
        "    enc_tag = meta_data[\"enc_tag\"]\n",
        "\n",
        "    num_pos = len(list(enc_pos.classes_))\n",
        "    num_tag = len(list(enc_tag.classes_))\n",
        "\n",
        "    sentence = \"\"\"\n",
        "    abhishek is going to india\n",
        "    \"\"\"\n",
        "    tokenized_sentence = config.TOKENIZER.encode(sentence)\n",
        "\n",
        "    sentence = sentence.split()\n",
        "    print(sentence)\n",
        "    print(tokenized_sentence)\n",
        "\n",
        "    test_dataset = dataset.EntityDataset(\n",
        "        texts=[sentence], \n",
        "        pos=[[0] * len(sentence)], \n",
        "        tags=[[0] * len(sentence)]\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = EntityModel(num_tag=num_tag, num_pos=num_pos)\n",
        "    model.load_state_dict(torch.load(config.MODEL_PATH))\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        data = test_dataset[0]\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device).unsqueeze(0)\n",
        "        tag, pos, _ = model(**data)\n",
        "\n",
        "        print(\n",
        "            enc_tag.inverse_transform(\n",
        "                tag.argmax(2).cpu().numpy().reshape(-1)\n",
        "            )[:len(tokenized_sentence)]\n",
        "        )\n",
        "        print(\n",
        "            enc_pos.inverse_transform(\n",
        "                pos.argmax(2).cpu().numpy().reshape(-1)\n",
        "            )[:len(tokenized_sentence)]\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Mnv9uCRvhO",
        "outputId": "39a015a9-842c-47a7-9427-4a9288b631a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import config\n",
        "import dataset\n",
        "import engine\n",
        "from model import EntityModel\n",
        "\n",
        "\n",
        "def process_data(data_path):\n",
        "    df = pd.read_csv(data_path, encoding=\"latin-1\")\n",
        "    df.loc[:, \"Sentence #\"] = df[\"Sentence #\"].fillna(method=\"ffill\")\n",
        "\n",
        "    enc_pos = preprocessing.LabelEncoder()\n",
        "    enc_tag = preprocessing.LabelEncoder()\n",
        "\n",
        "    df.loc[:, \"POS\"] = enc_pos.fit_transform(df[\"POS\"])\n",
        "    df.loc[:, \"Tag\"] = enc_tag.fit_transform(df[\"Tag\"])\n",
        "\n",
        "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
        "    pos = df.groupby(\"Sentence #\")[\"POS\"].apply(list).values\n",
        "    tag = df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values\n",
        "    return sentences, pos, tag, enc_pos, enc_tag\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sentences, pos, tag, enc_pos, enc_tag = process_data(config.TRAINING_FILE)\n",
        "    \n",
        "    meta_data = {\n",
        "        \"enc_pos\": enc_pos,\n",
        "        \"enc_tag\": enc_tag\n",
        "    }\n",
        "\n",
        "    joblib.dump(meta_data, \"meta.bin\")\n",
        "\n",
        "    num_pos = len(list(enc_pos.classes_))\n",
        "    num_tag = len(list(enc_tag.classes_))\n",
        "\n",
        "    (\n",
        "        train_sentences,\n",
        "        test_sentences,\n",
        "        train_pos,\n",
        "        test_pos,\n",
        "        train_tag,\n",
        "        test_tag\n",
        "    ) = model_selection.train_test_split(sentences, pos, tag, random_state=42, test_size=0.1)\n",
        "\n",
        "    train_dataset = dataset.EntityDataset(\n",
        "        texts=train_sentences, pos=train_pos, tags=train_tag\n",
        "    )\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4\n",
        "    )\n",
        "\n",
        "    valid_dataset = dataset.EntityDataset(\n",
        "        texts=test_sentences, pos=test_pos, tags=test_tag\n",
        "    )\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = EntityModel(num_tag=num_tag, num_pos=num_pos)\n",
        "    model.to(device)\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "            ],\n",
        "            \"weight_decay\": 0.001,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "            ],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    num_train_steps = int(len(train_sentences) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_loss = np.inf\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        train_loss = engine.train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
        "        test_loss = engine.eval_fn(valid_data_loader, model, device)\n",
        "        print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n",
        "        if test_loss < best_loss:\n",
        "            torch.save(model.state_dict(), config.MODEL_PATH)\n",
        "            best_loss = test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytXTA_ER3st",
        "outputId": "8b034d71-b218-4545-a1c6-92a8d863bcf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "mkdir input && cd input && wget https://github.com/bhuiyanmobasshir94/MultiCoNER/raw/main/data/ner_dataset.csv"
      ],
      "metadata": {
        "id": "FzHMETCvr_O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4080e51b-fb9d-4827-e448-c54826d64983"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-01-07 16:04:00--  https://github.com/bhuiyanmobasshir94/MultiCoNER/raw/main/data/ner_dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bhuiyanmobasshir94/MultiCoNER/main/data/ner_dataset.csv [following]\n",
            "--2022-01-07 16:04:01--  https://raw.githubusercontent.com/bhuiyanmobasshir94/MultiCoNER/main/data/ner_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15208151 (15M) [text/plain]\n",
            "Saving to: ‘ner_dataset.csv’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 4.73M 3s\n",
            "    50K .......... .......... .......... .......... ..........  0% 4.90M 3s\n",
            "   100K .......... .......... .......... .......... ..........  1% 22.7M 2s\n",
            "   150K .......... .......... .......... .......... ..........  1% 36.0M 2s\n",
            "   200K .......... .......... .......... .......... ..........  1% 7.42M 2s\n",
            "   250K .......... .......... .......... .......... ..........  2% 51.6M 2s\n",
            "   300K .......... .......... .......... .......... ..........  2% 37.0M 1s\n",
            "   350K .......... .......... .......... .......... ..........  2% 39.9M 1s\n",
            "   400K .......... .......... .......... .......... ..........  3% 66.8M 1s\n",
            "   450K .......... .......... .......... .......... ..........  3%  101M 1s\n",
            "   500K .......... .......... .......... .......... ..........  3% 10.2M 1s\n",
            "   550K .......... .......... .......... .......... ..........  4% 30.7M 1s\n",
            "   600K .......... .......... .......... .......... ..........  4%  125M 1s\n",
            "   650K .......... .......... .......... .......... ..........  4%  158M 1s\n",
            "   700K .......... .......... .......... .......... ..........  5% 71.9M 1s\n",
            "   750K .......... .......... .......... .......... ..........  5% 53.5M 1s\n",
            "   800K .......... .......... .......... .......... ..........  5% 92.7M 1s\n",
            "   850K .......... .......... .......... .......... ..........  6% 98.9M 1s\n",
            "   900K .......... .......... .......... .......... ..........  6%  152M 1s\n",
            "   950K .......... .......... .......... .......... ..........  6% 96.8M 1s\n",
            "  1000K .......... .......... .......... .......... ..........  7% 96.8M 1s\n",
            "  1050K .......... .......... .......... .......... ..........  7% 12.9M 1s\n",
            "  1100K .......... .......... .......... .......... ..........  7% 82.7M 1s\n",
            "  1150K .......... .......... .......... .......... ..........  8% 96.7M 1s\n",
            "  1200K .......... .......... .......... .......... ..........  8% 53.9M 1s\n",
            "  1250K .......... .......... .......... .......... ..........  8%  130M 1s\n",
            "  1300K .......... .......... .......... .......... ..........  9%  123M 1s\n",
            "  1350K .......... .......... .......... .......... ..........  9%  101M 1s\n",
            "  1400K .......... .......... .......... .......... ..........  9%  119M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 10%  124M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 10%  107M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 10% 87.0M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 11%  134M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 11%  127M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 11%  108M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 12% 84.7M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 12%  144M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 12%  150M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 13%  147M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 13%  123M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 13%  130M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 14%  146M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 14%  174M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 14%  133M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 15% 76.6M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 15% 99.8M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 15%  126M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 16%  125M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 16%  108M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 16%  106M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 17% 98.7M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 17% 88.4M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 17% 70.9M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 18%  103M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 18% 99.4M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 18% 82.8M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 19% 75.7M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 19% 98.8M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 19% 93.4M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 20%  101M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 20%  151M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 20%  136M 0s\n",
            "  3100K .......... .......... .......... .......... .......... 21%  146M 0s\n",
            "  3150K .......... .......... .......... .......... .......... 21%  111M 0s\n",
            "  3200K .......... .......... .......... .......... .......... 21%  151M 0s\n",
            "  3250K .......... .......... .......... .......... .......... 22%  151M 0s\n",
            "  3300K .......... .......... .......... .......... .......... 22%  105M 0s\n",
            "  3350K .......... .......... .......... .......... .......... 22%  132M 0s\n",
            "  3400K .......... .......... .......... .......... .......... 23% 88.7M 0s\n",
            "  3450K .......... .......... .......... .......... .......... 23%  134M 0s\n",
            "  3500K .......... .......... .......... .......... .......... 23%  121M 0s\n",
            "  3550K .......... .......... .......... .......... .......... 24% 66.0M 0s\n",
            "  3600K .......... .......... .......... .......... .......... 24%  137M 0s\n",
            "  3650K .......... .......... .......... .......... .......... 24% 84.4M 0s\n",
            "  3700K .......... .......... .......... .......... .......... 25%  127M 0s\n",
            "  3750K .......... .......... .......... .......... .......... 25% 53.3M 0s\n",
            "  3800K .......... .......... .......... .......... .......... 25% 93.6M 0s\n",
            "  3850K .......... .......... .......... .......... .......... 26% 97.9M 0s\n",
            "  3900K .......... .......... .......... .......... .......... 26% 82.8M 0s\n",
            "  3950K .......... .......... .......... .......... .......... 26% 69.7M 0s\n",
            "  4000K .......... .......... .......... .......... .......... 27%  127M 0s\n",
            "  4050K .......... .......... .......... .......... .......... 27%  149M 0s\n",
            "  4100K .......... .......... .......... .......... .......... 27%  111M 0s\n",
            "  4150K .......... .......... .......... .......... .......... 28%  111M 0s\n",
            "  4200K .......... .......... .......... .......... .......... 28% 85.1M 0s\n",
            "  4250K .......... .......... .......... .......... .......... 28%  142M 0s\n",
            "  4300K .......... .......... .......... .......... .......... 29%  168M 0s\n",
            "  4350K .......... .......... .......... .......... .......... 29% 93.8M 0s\n",
            "  4400K .......... .......... .......... .......... .......... 29%  156M 0s\n",
            "  4450K .......... .......... .......... .......... .......... 30% 97.4M 0s\n",
            "  4500K .......... .......... .......... .......... .......... 30%  167M 0s\n",
            "  4550K .......... .......... .......... .......... .......... 30% 96.7M 0s\n",
            "  4600K .......... .......... .......... .......... .......... 31% 96.0M 0s\n",
            "  4650K .......... .......... .......... .......... .......... 31%  136M 0s\n",
            "  4700K .......... .......... .......... .......... .......... 31%  136M 0s\n",
            "  4750K .......... .......... .......... .......... .......... 32%  147M 0s\n",
            "  4800K .......... .......... .......... .......... .......... 32%  118M 0s\n",
            "  4850K .......... .......... .......... .......... .......... 32%  134M 0s\n",
            "  4900K .......... .......... .......... .......... .......... 33%  108M 0s\n",
            "  4950K .......... .......... .......... .......... .......... 33%  125M 0s\n",
            "  5000K .......... .......... .......... .......... .......... 34%  102M 0s\n",
            "  5050K .......... .......... .......... .......... .......... 34%  116M 0s\n",
            "  5100K .......... .......... .......... .......... .......... 34%  138M 0s\n",
            "  5150K .......... .......... .......... .......... .......... 35%  106M 0s\n",
            "  5200K .......... .......... .......... .......... .......... 35%  135M 0s\n",
            "  5250K .......... .......... .......... .......... .......... 35%  149M 0s\n",
            "  5300K .......... .......... .......... .......... .......... 36%  137M 0s\n",
            "  5350K .......... .......... .......... .......... .......... 36% 81.3M 0s\n",
            "  5400K .......... .......... .......... .......... .......... 36%  154M 0s\n",
            "  5450K .......... .......... .......... .......... .......... 37%  141M 0s\n",
            "  5500K .......... .......... .......... .......... .......... 37%  133M 0s\n",
            "  5550K .......... .......... .......... .......... .......... 37%  125M 0s\n",
            "  5600K .......... .......... .......... .......... .......... 38% 99.2M 0s\n",
            "  5650K .......... .......... .......... .......... .......... 38%  140M 0s\n",
            "  5700K .......... .......... .......... .......... .......... 38%  121M 0s\n",
            "  5750K .......... .......... .......... .......... .......... 39%  140M 0s\n",
            "  5800K .......... .......... .......... .......... .......... 39%  121M 0s\n",
            "  5850K .......... .......... .......... .......... .......... 39%  135M 0s\n",
            "  5900K .......... .......... .......... .......... .......... 40%  110M 0s\n",
            "  5950K .......... .......... .......... .......... .......... 40%  133M 0s\n",
            "  6000K .......... .......... .......... .......... .......... 40%  115M 0s\n",
            "  6050K .......... .......... .......... .......... .......... 41%  160M 0s\n",
            "  6100K .......... .......... .......... .......... .......... 41% 81.3M 0s\n",
            "  6150K .......... .......... .......... .......... .......... 41%  140M 0s\n",
            "  6200K .......... .......... .......... .......... .......... 42%  163M 0s\n",
            "  6250K .......... .......... .......... .......... .......... 42%  107M 0s\n",
            "  6300K .......... .......... .......... .......... .......... 42%  170M 0s\n",
            "  6350K .......... .......... .......... .......... .......... 43% 79.3M 0s\n",
            "  6400K .......... .......... .......... .......... .......... 43%  143M 0s\n",
            "  6450K .......... .......... .......... .......... .......... 43%  110M 0s\n",
            "  6500K .......... .......... .......... .......... .......... 44%  156M 0s\n",
            "  6550K .......... .......... .......... .......... .......... 44%  136M 0s\n",
            "  6600K .......... .......... .......... .......... .......... 44%  130M 0s\n",
            "  6650K .......... .......... .......... .......... .......... 45% 91.8M 0s\n",
            "  6700K .......... .......... .......... .......... .......... 45%  157M 0s\n",
            "  6750K .......... .......... .......... .......... .......... 45%  103M 0s\n",
            "  6800K .......... .......... .......... .......... .......... 46%  165M 0s\n",
            "  6850K .......... .......... .......... .......... .......... 46%  163M 0s\n",
            "  6900K .......... .......... .......... .......... .......... 46%  101M 0s\n",
            "  6950K .......... .......... .......... .......... .......... 47%  104M 0s\n",
            "  7000K .......... .......... .......... .......... .......... 47%  145M 0s\n",
            "  7050K .......... .......... .......... .......... .......... 47%  163M 0s\n",
            "  7100K .......... .......... .......... .......... .......... 48% 98.6M 0s\n",
            "  7150K .......... .......... .......... .......... .......... 48%  106M 0s\n",
            "  7200K .......... .......... .......... .......... .......... 48%  165M 0s\n",
            "  7250K .......... .......... .......... .......... .......... 49%  164M 0s\n",
            "  7300K .......... .......... .......... .......... .......... 49%  132M 0s\n",
            "  7350K .......... .......... .......... .......... .......... 49% 93.1M 0s\n",
            "  7400K .......... .......... .......... .......... .......... 50%  113M 0s\n",
            "  7450K .......... .......... .......... .......... .......... 50%  154M 0s\n",
            "  7500K .......... .......... .......... .......... .......... 50%  145M 0s\n",
            "  7550K .......... .......... .......... .......... .......... 51%  123M 0s\n",
            "  7600K .......... .......... .......... .......... .......... 51% 99.5M 0s\n",
            "  7650K .......... .......... .......... .......... .......... 51%  134M 0s\n",
            "  7700K .......... .......... .......... .......... .......... 52%  152M 0s\n",
            "  7750K .......... .......... .......... .......... .......... 52% 87.6M 0s\n",
            "  7800K .......... .......... .......... .......... .......... 52%  165M 0s\n",
            "  7850K .......... .......... .......... .......... .......... 53%  166M 0s\n",
            "  7900K .......... .......... .......... .......... .......... 53%  113M 0s\n",
            "  7950K .......... .......... .......... .......... .......... 53% 81.6M 0s\n",
            "  8000K .......... .......... .......... .......... .......... 54%  129M 0s\n",
            "  8050K .......... .......... .......... .......... .......... 54%  129M 0s\n",
            "  8100K .......... .......... .......... .......... .......... 54%  145M 0s\n",
            "  8150K .......... .......... .......... .......... .......... 55% 86.8M 0s\n",
            "  8200K .......... .......... .......... .......... .......... 55%  133M 0s\n",
            "  8250K .......... .......... .......... .......... .......... 55%  121M 0s\n",
            "  8300K .......... .......... .......... .......... .......... 56%  144M 0s\n",
            "  8350K .......... .......... .......... .......... .......... 56% 95.2M 0s\n",
            "  8400K .......... .......... .......... .......... .......... 56%  117M 0s\n",
            "  8450K .......... .......... .......... .......... .......... 57%  159M 0s\n",
            "  8500K .......... .......... .......... .......... .......... 57%  155M 0s\n",
            "  8550K .......... .......... .......... .......... .......... 57%  115M 0s\n",
            "  8600K .......... .......... .......... .......... .......... 58%  103M 0s\n",
            "  8650K .......... .......... .......... .......... .......... 58%  138M 0s\n",
            "  8700K .......... .......... .......... .......... .......... 58%  163M 0s\n",
            "  8750K .......... .......... .......... .......... .......... 59%  135M 0s\n",
            "  8800K .......... .......... .......... .......... .......... 59%  113M 0s\n",
            "  8850K .......... .......... .......... .......... .......... 59% 91.8M 0s\n",
            "  8900K .......... .......... .......... .......... .......... 60%  133M 0s\n",
            "  8950K .......... .......... .......... .......... .......... 60%  143M 0s\n",
            "  9000K .......... .......... .......... .......... .......... 60%  107M 0s\n",
            "  9050K .......... .......... .......... .......... .......... 61%  151M 0s\n",
            "  9100K .......... .......... .......... .......... .......... 61%  161M 0s\n",
            "  9150K .......... .......... .......... .......... .......... 61%  110M 0s\n",
            "  9200K .......... .......... .......... .......... .......... 62% 91.8M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 62%  136M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 62%  122M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 63%  100M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 63%  113M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 63%  132M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 64%  125M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 64%  143M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 64% 94.1M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 65%  158M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 65%  158M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 65%  131M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 66%  128M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 66%  149M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 66% 84.4M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 67%  144M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 67%  158M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 68% 86.0M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 68%  144M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 68%  111M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 69%  131M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 69%  114M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 69%  121M 0s\n",
            " 10350K .......... .......... .......... .......... .......... 70%  128M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 70%  141M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 70%  102M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 71%  148M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 71% 67.6M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 71%  100M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 72%  129M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 72% 92.3M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 72% 81.0M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 73%  105M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 73%  137M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 73%  144M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 74% 88.2M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 74%  120M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 74% 92.2M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 75%  150M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 75%  127M 0s\n",
            " 11200K .......... .......... .......... .......... .......... 75%  108M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 76%  125M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 76%  148M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 76%  135M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 77%  145M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 77%  114M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 77%  158M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 78%  111M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 78% 76.6M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 78%  108M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 79%  152M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 79%  115M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 79%  144M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 80%  150M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 80%  134M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 80%  135M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 81%  152M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 81%  149M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 81%  155M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 82%  136M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 82%  121M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 82%  151M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 83%  142M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 83%  121M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 83%  159M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 84%  157M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 84%  146M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 84%  133M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 85%  137M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 85%  141M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 85%  149M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 86%  134M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 86%  142M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 86%  151M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 87%  148M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 87%  130M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 87%  132M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 88%  142M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 88%  148M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 88%  137M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 89%  145M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 89%  151M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 89%  138M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 90%  115M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 90%  149M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 90%  154M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 91%  142M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 91%  132M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 91%  163M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 92%  144M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 92%  164M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 92%  133M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 93%  137M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 93%  161M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 93%  163M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 94%  132M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 94%  165M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 94%  168M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 95%  136M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 95%  140M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 95%  169M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 96%  133M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 96%  165M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 96%  145M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 97%  149M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 97%  170M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 97%  158M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 98% 96.7M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 98%  166M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 98%  162M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 99%  149M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 99%  147M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 99%  156M 0s\n",
            " 14850K .                                                     100% 3261G=0.2s\n",
            "\n",
            "2022-01-07 16:04:01 (90.0 MB/s) - ‘ner_dataset.csv’ saved [15208151/15208151]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python train.py "
      ],
      "metadata": {
        "id": "xEQGaaIzS_Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python predict.py "
      ],
      "metadata": {
        "id": "OlaOtUdfVbNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}